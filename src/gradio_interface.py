# -*- coding: utf-8 -*-
"""Interfaz de usuario con Gradio"""

import gradio as gr
import torch
from typing import List
from .rag_system import PDFRAGSystem
from .config import *

class GradioInterface:
    def __init__(self, rag_system: PDFRAGSystem):
        self.rag = rag_system

    def create_interface(self):
        """Crea la interfaz de Gradio"""
        print("\n" + "="*60)
        print("ğŸ“¤ CREANDO INTERFAZ GRADIO...")
        print("="*60)

        with gr.Blocks(title="RAG Hispanidad", theme=gr.themes.Soft()) as demo:
            # Estado
            chat_history = gr.State([])

            # TÃ­tulo
            gr.Markdown("## ğŸ¤– **RAG Hispanidad - Chat con PDFs HistÃ³ricos**")
            gr.Markdown("Sube PDFs histÃ³ricos y conversa con ellos usando inteligencia artificial")

            # Chatbot
            chatbot = gr.Chatbot(
                label="ğŸ’¬ ConversaciÃ³n",
                height=450,
                bubble_full_width=False
            )

            # Ãrea de entrada
            user_input = gr.Textbox(
                label="Tu pregunta sobre historia hispÃ¡nica",
                placeholder="Ej: Â¿QuÃ© documentos tienes sobre la Leyenda Negra espaÃ±ola?",
                lines=3,
                max_lines=5
            )

            # Botones principales
            with gr.Row():
                submit_btn = gr.Button("ğŸ“¤ Enviar pregunta", variant="primary", size="lg")
                clear_btn = gr.Button("ğŸ—‘ï¸ Limpiar chat", variant="secondary")
                test_btn = gr.Button("ğŸ§ª Probar sistema", variant="secondary")

            # Panel izquierdo: GestiÃ³n de documentos
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“„ **GestiÃ³n de PDFs**")

                    pdf_upload = gr.File(
                        label="Arrastra o selecciona PDFs histÃ³ricos",
                        file_types=[".pdf"],
                        file_count="multiple",
                        height=100
                    )

                    with gr.Row():
                        pdf_process_btn = gr.Button("ğŸ”§ Procesar PDFs", variant="primary")
                        pdf_clear_btn = gr.Button("Limpiar", variant="secondary")

                    pdf_status = gr.Textbox(
                        label="Estado de procesamiento",
                        value="Listo para recibir PDFs...",
                        interactive=False,
                        lines=3
                    )

                # Panel derecho: Sistema y estadÃ­sticas
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“Š **Estado del Sistema**")

                    stats_display = gr.Textbox(
                        label="EstadÃ­sticas en tiempo real",
                        value="Calculando...",
                        interactive=False,
                        lines=6
                    )

                    gr.Markdown("### âš™ï¸ **ConfiguraciÃ³n**")

                    response_length = gr.Slider(
                        minimum=500,
                        maximum=MAX_RESPONSE_LENGTH,
                        value=DEFAULT_RESPONSE_LENGTH,
                        step=100,
                        label="ğŸ“ Longitud de respuesta"
                    )

                    refresh_btn = gr.Button("ğŸ”„ Actualizar estadÃ­sticas", variant="secondary")

            # InformaciÃ³n del sistema
            gr.Markdown("---")
            gr.Markdown(f"""
            ### ğŸ›ï¸ **Sistema RAG Hispanidad**
            - **Modelo:** {MODEL_NAME}
            - **Embeddings:** {EMBEDDING_MODEL}
            - **Base de datos:** ChromaDB persistente en Google Drive
            - **GPU:** {'âœ… Disponible' if torch.cuda.is_available() else 'âŒ Solo CPU'}
            """)

            # ===== CONEXIONES =====
            # 1. CHAT PRINCIPAL
            submit_btn.click(
                fn=self.chat_function,
                inputs=[user_input, chat_history, response_length],
                outputs=[chatbot, user_input]
            )

            user_input.submit(
                fn=self.chat_function,
                inputs=[user_input, chat_history, response_length],
                outputs=[chatbot, user_input]
            )

            # 2. BOTÃ“N DE PRUEBA
            test_btn.click(
                fn=self.test_system_function,
                inputs=[user_input, chat_history],
                outputs=[chatbot, user_input]
            )

            # 3. PROCESAMIENTO DE PDFs
            pdf_process_btn.click(
                fn=self.process_pdfs_function,
                inputs=[pdf_upload],
                outputs=[pdf_status, stats_display]
            )

            # 4. BOTONES DE LIMPIEZA
            clear_btn.click(
                fn=lambda: [],
                outputs=[chatbot]
            )

            pdf_clear_btn.click(
                fn=lambda: None,
                outputs=[pdf_upload]
            )

            # 5. ACTUALIZACIÃ“N DE ESTADÃSTICAS
            refresh_btn.click(
                fn=self.get_system_stats,
                outputs=[stats_display]
            )

            # 6. CARGA INICIAL
            demo.load(
                fn=self.get_system_stats,
                outputs=[stats_display]
            )

        return demo

    def chat_function(self, message: str, history: List, max_chars: int):
        """FunciÃ³n principal del chat"""
        print(f"\n{'='*60}")
        print(f"ğŸ”” CHAT LLAMADO: '{message[:80]}...'")

        try:
            # 1. Buscar documentos relevantes
            print("   ğŸ” Buscando en documentos...")
            docs = self.rag.search_documents(message, n_results=3)
            print(f"   ğŸ“š Documentos encontrados: {len(docs)}")

            # 2. Generar respuesta
            if docs:
                print(f"   ğŸ¤– Generando respuesta ({max_chars} caracteres mÃ¡x)...")
                response = self.rag.generate_response(message, docs, max_chars)
                print(f"   âœ… Respuesta generada: {len(response):,} caracteres")
            else:
                response = """ğŸ“­ **No encontrÃ© documentos relevantes en la base de datos.**

ğŸ’¡ **Sugerencias:**
1. Sube PDFs histÃ³ricos usando el panel izquierdo
2. Haz clic en "Procesar PDFs" para indexarlos
3. Reformula tu pregunta usando tÃ©rminos histÃ³ricos"""
                print("   âš ï¸  No se encontraron documentos")

            # 3. Actualizar historial
            history.append([message, response])

            print(f"   ğŸ“Š Historial actualizado: {len(history)} intercambios")
            print(f"{'='*60}")

            return history, ""

        except Exception as e:
            print(f"âŒ ERROR en chat_function: {type(e).__name__}: {e}")
            error_msg = f"""âš ï¸ **Error en el sistema**

**Detalles:** {str(e)[:150]}"""
            history.append([message, error_msg])
            print(f"{'='*60}")
            return history, ""

    def process_pdfs_function(self, files):
        """Procesar PDFs - maneja mÃºltiples archivos"""
        if not files:
            return "âŒ No se seleccionaron archivos", self.get_system_stats()

        print(f"\n{'='*60}")
        print(f"ğŸ“¤ PROCESANDO {len(files)} PDFs...")

        results = []
        total_chunks = 0

        for i, file in enumerate(files):
            print(f"   [{i+1}/{len(files)}] Procesando...")
            result = self.rag.upload_and_process_pdf(file)

            if result.get('success', False):
                chunks = result.get('chunks_added', 0)
                total_chunks += chunks
                results.append(f"âœ… {result.get('filename', 'PDF')}: {chunks} chunks")
            else:
                results.append(f"âŒ {result.get('filename', 'PDF')}: {result.get('error', 'Error')}")

        # Actualizar estadÃ­sticas
        self.rag.update_stats()
        stats = self.rag.get_system_info()

        # Crear resumen
        if total_chunks > 0:
            summary = f"âœ… {len(files)} PDFs procesados, {total_chunks} chunks aÃ±adidos"
        else:
            summary = f"âš ï¸  {len(files)} PDFs procesados, 0 chunks aÃ±adidos"

        print(f"ğŸ“Š RESUMEN: {summary}")
        print(f"{'='*60}")

        result_text = f"**Resultados del procesamiento:**\n\n" + "\n".join(results[:10])
        if len(results) > 10:
            result_text += f"\n\n... y {len(results) - 10} mÃ¡s"

        return result_text, self.format_stats_detailed(stats)

    def test_system_function(self, message: str, history: List):
        """FunciÃ³n de prueba del sistema"""
        print(f"\nğŸ§ª PRUEBA DEL SISTEMA: '{message}'")

        test_response = f"""ğŸ§ª **Prueba del sistema completada**

âœ… **Componentes verificados:**
â€¢ Modelo salamandra-2b: {'ğŸŸ¢ Operativo' if self.rag.chat_engine.model else 'ğŸ”´ No disponible'}
â€¢ Base de vectores: {self.rag.vector_store.get_stats().get('total_chunks', 0):,} chunks
â€¢ Embeddings: {'ğŸŸ¢ Operativo' if self.rag.chat_engine.embedder else 'ğŸ”´ No disponible'}
â€¢ GPU: {'ğŸŸ¢ Disponible' if torch.cuda.is_available() else 'ğŸŸ¡ Solo CPU'}

ğŸ“Š **EstadÃ­sticas actuales:**
{self.rag.get_system_info().get('total_pdfs', 0)} PDFs procesados
{self
